{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92cd56f3",
   "metadata": {},
   "source": [
    "# **Advanced RAG Technique**\n",
    "\n",
    "In this document we use RAG with hybrid search (sparse retriever & dense retriever) and contextual compression on the retrieved documents.\n",
    "We use GPT3.5 Turbo as LLM, and BM25 & OpenAI Embeddings with Chroma as sparse and dense retriever.\n",
    "\n",
    "How to use:\n",
    "Make sure you have executed the Embedding-OpenAI-Chroma.ipynb, to generate a folder /Chroma/ which contains the vector database. Link the folder in the following sections accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4023c442",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\burha\\miniconda3\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\burha\\miniconda3\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from evaluate) (0.20.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from evaluate) (4.66.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\burha\\miniconda3\\lib\\site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from evaluate) (2.1.4)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\burha\\miniconda3\\lib\\site-packages (from evaluate) (2.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from evaluate) (1.26.3)\n",
      "Requirement already satisfied: dill in c:\\users\\burha\\miniconda3\\lib\\site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\burha\\miniconda3\\lib\\site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\burha\\miniconda3\\lib\\site-packages (from evaluate) (2023.10.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\burha\\miniconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\burha\\miniconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\burha\\miniconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.19.0->evaluate) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from pandas->evaluate) (2023.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\burha\\miniconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\burha\\miniconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\burha\\miniconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\burha\\miniconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\burha\\miniconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: rouge_score in c:\\users\\burha\\miniconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\burha\\miniconda3\\lib\\site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from rouge_score) (1.26.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from nltk->rouge_score) (2023.12.25)\n",
      "Requirement already satisfied: joblib in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from nltk->rouge_score) (1.3.2)\n",
      "Requirement already satisfied: click in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from nltk->rouge_score) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk->rouge_score) (0.4.6)\n",
      "Collecting bert_score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 61.1/61.1 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=4.31.1 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from bert_score) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from bert_score) (2.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from bert_score) (1.26.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from bert_score) (4.35.2)\n",
      "Requirement already satisfied: requests in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from bert_score) (2.31.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from bert_score) (2.1.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\burha\\miniconda3\\lib\\site-packages (from bert_score) (3.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from bert_score) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.0.1->bert_score) (2023.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.0.1->bert_score) (2023.3.post1)\n",
      "Requirement already satisfied: sympy in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.0.0->bert_score) (1.12)\n",
      "Requirement already satisfied: filelock in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.0.0->bert_score) (3.13.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.0.0->bert_score) (3.1.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.0.0->bert_score) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.0.0->bert_score) (4.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\burha\\miniconda3\\lib\\site-packages (from torch>=1.0.0->bert_score) (2023.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.31.1->bert_score) (0.4.6)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from transformers>=3.0.0->bert_score) (0.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from transformers>=3.0.0->bert_score) (6.0.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from transformers>=3.0.0->bert_score) (0.15.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from transformers>=3.0.0->bert_score) (0.20.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from transformers>=3.0.0->bert_score) (2023.12.25)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\burha\\miniconda3\\lib\\site-packages (from matplotlib->bert_score) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\burha\\miniconda3\\lib\\site-packages (from matplotlib->bert_score) (4.39.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\burha\\miniconda3\\lib\\site-packages (from matplotlib->bert_score) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\burha\\miniconda3\\lib\\site-packages (from matplotlib->bert_score) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->bert_score) (10.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\burha\\miniconda3\\lib\\site-packages (from matplotlib->bert_score) (1.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from requests->bert_score) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from requests->bert_score) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from requests->bert_score) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from requests->bert_score) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\burha\\appdata\\roaming\\python\\python310\\site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Installing collected packages: bert_score\n",
      "Successfully installed bert_score-0.3.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement bleu_score (from versions: none)\n",
      "ERROR: No matching distribution found for bleu_score\n"
     ]
    }
   ],
   "source": [
    "!pip -q install langchain openai chromadb sentence_transformers evaluate rouge_score bert_score bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdd4550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9b0ad0",
   "metadata": {},
   "source": [
    "## **OpenAI Authenticatation**\n",
    "We use OpenAIs GPT3.5 Turbo. Make sure to have balance on your OpenAI Dashboard and create a personal secret key at https://platform.openai.com/api-keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa6daf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bca64d",
   "metadata": {},
   "source": [
    "## **Load Chroma and GPT3.5 Turbo LLM**\n",
    "We first load the Chroma vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c6a730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings,GPT4AllEmbeddings,HuggingFaceBgeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a7d37a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './Chroma/chroma_openai' exists, perfect!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#Here we can check if the folder exists\n",
    "persist_directory = \"./Chroma/chroma_openai\"\n",
    "# Create the directory if it does not exist\n",
    "if not os.path.exists(persist_directory):\n",
    "    print(f\"Please execute first LangChainRAG/Embedding-OpenAI-Chroma.ipynb, we didn't find any Chroma vector storage.\")\n",
    "else:\n",
    "    print(f\"Directory '{persist_directory}' exists, perfect!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0046687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.schema import Document\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class HybridSearch:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        os.environ['OPENAI_API_KEY'] = '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'\n",
    "        self.embedding = OpenAIEmbeddings()\n",
    "        self.ensemble_retriever = None\n",
    "\n",
    "    def load_data(self):\n",
    "        with open(self.data_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "\n",
    "    def initialize_bm25_retriever(self, docs):\n",
    "        if not all(isinstance(doc, Document) for doc in docs):\n",
    "            raise ValueError(\"All items in docs must be Document instances.\")\n",
    "        abstracts = [doc.page_content for doc in docs]\n",
    "        bm25_retriever = BM25Retriever.from_texts(abstracts, metadatas=[doc.metadata for doc in docs])\n",
    "        bm25_retriever.k = 3\n",
    "        return bm25_retriever\n",
    "\n",
    "    def transform_data_to_documents(self, data):\n",
    "        docs = []\n",
    "        for doc in data:\n",
    "            title = doc.get('title', {}).get('full_text', '')\n",
    "            abstract = doc.get('abstract', {}).get('full_text', '')\n",
    "            keywords = doc.get('keywords', [[]])[0] if doc['keywords'] and isinstance(doc['keywords'][0], list) else []\n",
    "            document = Document(page_content=abstract, metadata={'title': title, 'keywords': keywords})\n",
    "            docs.append(document)\n",
    "        return docs\n",
    "\n",
    "    def process_documents_with_chroma(self, docs):\n",
    "        persist_directory = './Chroma/chroma_openai'\n",
    "        db3 = Chroma(persist_directory=persist_directory, embedding_function=self.embedding)\n",
    "        if not all(isinstance(doc, Document) for doc in docs):\n",
    "            raise ValueError(\"All items in docs must be Document instances.\")\n",
    "        chroma_retriever = db3.as_retriever(search_kwargs={'k': 3})\n",
    "        return chroma_retriever\n",
    "\n",
    "    def create_ensemble_retriever(self, bm25_retriever, chroma_retriever):\n",
    "        # faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={'k': 10})\n",
    "        ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, chroma_retriever], weights=[0.7, 0.3])\n",
    "        self.ensemble_retriever = ensemble_retriever\n",
    "\n",
    "    def get_relevant_documents(self, query):\n",
    "        results = self.ensemble_retriever.get_relevant_documents(query)\n",
    "        print(results)\n",
    "        formatted_results = []\n",
    "        for document in results:\n",
    "            doc_info = {\n",
    "                'title': document.metadata.get('title', document.metadata.get('source/title','No Title')),\n",
    "                'keywords': document.metadata.get('keywords', []),\n",
    "                'abstract': document.page_content\n",
    "            }\n",
    "            formatted_results.append(doc_info)\n",
    "        return formatted_results\n",
    "\n",
    "hs = HybridSearch(\n",
    "        '../papers.json')\n",
    "data = hs.load_data()\n",
    "docs = hs.transform_data_to_documents(data)\n",
    "bm25_retriever = hs.initialize_bm25_retriever(docs)\n",
    "\n",
    "chroma_vectorstore = hs.process_documents_with_chroma(docs)\n",
    "hs.create_ensemble_retriever(bm25_retriever, chroma_vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f628b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# Here we prepare the hybrid-search retriever, the prompt, and the LLM.\n",
    "\n",
    "retriever = hs.ensemble_retriever\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83a58d",
   "metadata": {},
   "source": [
    "## **Generate answers using contextual compression**\n",
    "Here we use LLMChainExtractor to only take the relevant information from each document. We prepare the compressor based retriever and generate answers in an analogous way as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f575ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor,LLMChainFilter\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Here we prepare the Contextual Retriever\n",
    "compressor = LLMChainExtractor.from_llm(\n",
    "    llm=llm\n",
    ")\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d749305",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain_compressor = (\n",
    "    {\"context\": compression_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75c1b65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______\n",
      "[Document(page_content='surgical practice in gastro-enterology is concerned by deep technological advances. in the past century, the technological advances were conducted by clinical challenges and strategies. the 21th century is clearly led by the inversion of the paradigms. medical practice does not only depend on the access to the technologies, but it seems submitted to her. should the physician follow the engineer ? does the clinical data collection, depend on the computer ? who decides ? the doctor, the patient or the artificial intelligence ? materiel et methods : the present essay that definitely does not answer all these questions, is achieved thanks the practical experience of our colleagues. we also collected the recent literature devoted to new and promising technologies. the pubmed review is completed by several think tanks reports coming from the industry.', metadata={'title': '[recent advances in digestive surgery].', 'keywords': ['Artificial intelligence', 'Augmented reality', 'Big data', 'surgical progresses']}), Document(page_content='protein engineering and characterisation of non-synonymous single nucleotide variants (snvs) require accurate prediction of protein stability changes (δδgu) induced by single amino acid substitutions. here, we have developed a new prediction method called evolutionary, amino acid, and structural encodings with multiple models (ease-mm), which comprises five specialised support vector machine (svm) models and makes the final prediction from a consensus of two models selected based on the predicted secondary structure and accessible surface area of the mutated residue. the new method is applicable to single-domain monomeric proteins and can predict δδgu with a protein sequence and mutation as the only inputs. ease-mm yielded a pearson correlation coefficient of 0.53-0.59 in 10-fold cross-validation and independent testing and was able to outperform other sequence-based methods. when compared to structure-based energy functions, ease-mm achieved a comparable or better performance. the application to a large dataset of human germline non-synonymous snvs showed that the disease-causing variants tend to be associated with larger magnitudes of δδgu predicted with ease-mm. the ease-mm web-server is available at http://sparks-lab.org/server/ease.', metadata={'title': 'ease-mm: sequence-based prediction of mutation-induced stability changes with feature-based multiple models.', 'keywords': ['amino acid substitution', 'free energy change', 'machine learning', 'missense mutation', 'non-synonymous SNV']}), Document(page_content='hierarchy is a recurrent feature of social life. from an early age, children are confronted with power relationships wherein a dominant individual imposes his/her will to a subordinate individual. recent research has shown that young children develop sophisticated abilities in understanding power. however, little is known about how young children react to power-based inequality. do they consider a dominant should be favored so as to strenghten the status quo\\xa0? or do they consider that the subordinate must be favored to conteract a social inequality? in the current paper, i present and discuss a recent study, published in developmental psychology, that investigates this issue.', metadata={'title': \"[children's politics and the hierarchy dilemma].\", 'keywords': []}), Document(page_content='br (mae = 2.044 mpa, rmse = 3.180) results are better than the dt (mae = 4.136 mpa, rmse = 6.256 mpa) and gep (mae = 3.102 mpa, rmse = 4.049 mpa). the application of sml techniques will benefit the construction sector with fast and cost-effective methods for estimating the properties of materials.', metadata={'keywords': 'compressive strength, concrete, geopolymers, modeling, predictions', 'seq_num': 129453, 'source/title': 'evaluation of artificial intelligence methods to estimate the compressive strength of geopolymers.'}), Document(page_content='automated processing took ≈1.1\\xa0seconds for a typical case. on the scan-rescan data set, the model exceeded the precision of human expert (coefficient of variation 7.2% versus 11.1% for gl-shortening, <i>p</i>=0.0024; 6.5% versus 9.1% for mapse, <i>p</i>=0.0124). the minimal detectable change at 90% power was 2.53 percentage points for gl-shortening and 1.84\\xa0mm for mapse. ai gl-shortening correlated well with manual global longitudinal strain (<i>r</i><sup>2</sup>=0.85). ai mapse had the strongest association with outcomes (χ<sup>2</sup>, 255; hazard ratio [hr], 2.5 [95% ci, 2.2-2.8]), compared with ai gl-shortening (χ<sup>2</sup>, 197; hr, 2.1 [95% ci,1.9-2.4]), manual global longitudinal strain (χ<sup>2</sup>, 192; hr, 2.1 [95% ci, 1.9-2.3]), and left ventricular ejection fraction (χ<sup>2</sup>, 147; hr, 1.8 [95% ci, 1.6-1.9]), with <i>p</i><0.001 for all. conclusions automated in-line ai-measured mapse and gl-shortening can deliver immediate and highly reproducible results during', metadata={'keywords': 'artificial intelligence, cardiac magnetic resonance imaging, global longitudinal shortening, reproducibility, image processing, prognosis', 'seq_num': 121041, 'source/title': 'automated in-line artificial intelligence measured global longitudinal shortening and mitral annular plane systolic excursion: reproducibility and prognostic significance.'}), Document(page_content=\"the diagnostic accuracy of exercise stress echocardiography (ese) for myocardial ischemia requires improvement, given that it currently depends on the physicians' experience and image quality. to address this issue, we aimed to develop artificial intelligence (ai)-based slow-motion echocardiography using inter-image interpolation. the clinical usefulness of this method was evaluated for detecting regional wall-motion abnormalities (rwmas). in this study, an ai-based echocardiographic image-interpolation pipeline was developed using optical flow calculation and prediction for in-between images. the accuracy for detecting rwmas and image readability among 25 patients with rwma and 25 healthy volunteers was compared between four cardiologists using slow-motion and conventional ese. slow-motion echocardiography was successfully developed for arbitrary time-steps (e.g., 0.125×, and 0.5×) using 1,334 videos. the rwma detection accuracy showed a numerical improvement, but it was not\", metadata={'keywords': 'Artificial intelligence, Deep learning, Ischemic heart disease, Regional wall motion abnormality, Stress echocardiography', 'seq_num': 178963, 'source/title': 'development of artificial intelligence-based slow-motion echocardiography and clinical usefulness for evaluating regional wall motion abnormalities.'})]\n",
      "Document: {'title': '[recent advances in digestive surgery].', 'keywords': ['Artificial intelligence', 'Augmented reality', 'Big data', 'surgical progresses'], 'abstract': 'surgical practice in gastro-enterology is concerned by deep technological advances. in the past century, the technological advances were conducted by clinical challenges and strategies. the 21th century is clearly led by the inversion of the paradigms. medical practice does not only depend on the access to the technologies, but it seems submitted to her. should the physician follow the engineer ? does the clinical data collection, depend on the computer ? who decides ? the doctor, the patient or the artificial intelligence ? materiel et methods : the present essay that definitely does not answer all these questions, is achieved thanks the practical experience of our colleagues. we also collected the recent literature devoted to new and promising technologies. the pubmed review is completed by several think tanks reports coming from the industry.'}\n",
      "\n",
      "Document: {'title': 'ease-mm: sequence-based prediction of mutation-induced stability changes with feature-based multiple models.', 'keywords': ['amino acid substitution', 'free energy change', 'machine learning', 'missense mutation', 'non-synonymous SNV'], 'abstract': 'protein engineering and characterisation of non-synonymous single nucleotide variants (snvs) require accurate prediction of protein stability changes (δδgu) induced by single amino acid substitutions. here, we have developed a new prediction method called evolutionary, amino acid, and structural encodings with multiple models (ease-mm), which comprises five specialised support vector machine (svm) models and makes the final prediction from a consensus of two models selected based on the predicted secondary structure and accessible surface area of the mutated residue. the new method is applicable to single-domain monomeric proteins and can predict δδgu with a protein sequence and mutation as the only inputs. ease-mm yielded a pearson correlation coefficient of 0.53-0.59 in 10-fold cross-validation and independent testing and was able to outperform other sequence-based methods. when compared to structure-based energy functions, ease-mm achieved a comparable or better performance. the application to a large dataset of human germline non-synonymous snvs showed that the disease-causing variants tend to be associated with larger magnitudes of δδgu predicted with ease-mm. the ease-mm web-server is available at http://sparks-lab.org/server/ease.'}\n",
      "\n",
      "Document: {'title': \"[children's politics and the hierarchy dilemma].\", 'keywords': [], 'abstract': 'hierarchy is a recurrent feature of social life. from an early age, children are confronted with power relationships wherein a dominant individual imposes his/her will to a subordinate individual. recent research has shown that young children develop sophisticated abilities in understanding power. however, little is known about how young children react to power-based inequality. do they consider a dominant should be favored so as to strenghten the status quo\\xa0? or do they consider that the subordinate must be favored to conteract a social inequality? in the current paper, i present and discuss a recent study, published in developmental psychology, that investigates this issue.'}\n",
      "\n",
      "Document: {'title': 'evaluation of artificial intelligence methods to estimate the compressive strength of geopolymers.', 'keywords': 'compressive strength, concrete, geopolymers, modeling, predictions', 'abstract': 'br (mae = 2.044 mpa, rmse = 3.180) results are better than the dt (mae = 4.136 mpa, rmse = 6.256 mpa) and gep (mae = 3.102 mpa, rmse = 4.049 mpa). the application of sml techniques will benefit the construction sector with fast and cost-effective methods for estimating the properties of materials.'}\n",
      "\n",
      "Document: {'title': 'automated in-line artificial intelligence measured global longitudinal shortening and mitral annular plane systolic excursion: reproducibility and prognostic significance.', 'keywords': 'artificial intelligence, cardiac magnetic resonance imaging, global longitudinal shortening, reproducibility, image processing, prognosis', 'abstract': 'automated processing took ≈1.1\\xa0seconds for a typical case. on the scan-rescan data set, the model exceeded the precision of human expert (coefficient of variation 7.2% versus 11.1% for gl-shortening, <i>p</i>=0.0024; 6.5% versus 9.1% for mapse, <i>p</i>=0.0124). the minimal detectable change at 90% power was 2.53 percentage points for gl-shortening and 1.84\\xa0mm for mapse. ai gl-shortening correlated well with manual global longitudinal strain (<i>r</i><sup>2</sup>=0.85). ai mapse had the strongest association with outcomes (χ<sup>2</sup>, 255; hazard ratio [hr], 2.5 [95% ci, 2.2-2.8]), compared with ai gl-shortening (χ<sup>2</sup>, 197; hr, 2.1 [95% ci,1.9-2.4]), manual global longitudinal strain (χ<sup>2</sup>, 192; hr, 2.1 [95% ci, 1.9-2.3]), and left ventricular ejection fraction (χ<sup>2</sup>, 147; hr, 1.8 [95% ci, 1.6-1.9]), with <i>p</i><0.001 for all. conclusions automated in-line ai-measured mapse and gl-shortening can deliver immediate and highly reproducible results during'}\n",
      "\n",
      "Document: {'title': 'development of artificial intelligence-based slow-motion echocardiography and clinical usefulness for evaluating regional wall motion abnormalities.', 'keywords': 'Artificial intelligence, Deep learning, Ischemic heart disease, Regional wall motion abnormality, Stress echocardiography', 'abstract': \"the diagnostic accuracy of exercise stress echocardiography (ese) for myocardial ischemia requires improvement, given that it currently depends on the physicians' experience and image quality. to address this issue, we aimed to develop artificial intelligence (ai)-based slow-motion echocardiography using inter-image interpolation. the clinical usefulness of this method was evaluated for detecting regional wall-motion abnormalities (rwmas). in this study, an ai-based echocardiographic image-interpolation pipeline was developed using optical flow calculation and prediction for in-between images. the accuracy for detecting rwmas and image readability among 25 patients with rwma and 25 healthy volunteers was compared between four cardiologists using slow-motion and conventional ese. slow-motion echocardiography was successfully developed for arbitrary time-steps (e.g., 0.125×, and 0.5×) using 1,334 videos. the rwma detection accuracy showed a numerical improvement, but it was not\"}\n",
      "\n",
      "_______\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\burha\\miniconda3\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\burha\\miniconda3\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\burha\\miniconda3\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\burha\\miniconda3\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\burha\\miniconda3\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\burha\\miniconda3\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Ease-mm is a new prediction method called evolutionary, amino acid, and structural encodings with multiple models (ease-mm), which comprises five specialised support vector machine (svm) models and makes the final prediction from a consensus of two models selected based on the predicted secondary structure and accessible surface area of the mutated residue. Ease-mm yielded a pearson correlation coefficient of 0.53-0.59 in 10-fold cross-validation and independent testing and was able to outperform other sequence-based methods. Ease-mm achieved a comparable or better performance when compared to structure-based energy functions. The application to a large dataset of human germline non-synonymous snvs showed that the disease-causing variants tend to be associated with larger magnitudes of δδgu predicted with ease-mm.', metadata={'title': 'ease-mm: sequence-based prediction of mutation-induced stability changes with feature-based multiple models.', 'keywords': ['amino acid substitution', 'free energy change', 'machine learning', 'missense mutation', 'non-synonymous SNV']}), Document(page_content='automated in-line ai-measured mapse and gl-shortening can deliver immediate and highly reproducible results during', metadata={'keywords': 'artificial intelligence, cardiac magnetic resonance imaging, global longitudinal shortening, reproducibility, image processing, prognosis', 'seq_num': 121041, 'source/title': 'automated in-line artificial intelligence measured global longitudinal shortening and mitral annular plane systolic excursion: reproducibility and prognostic significance.'})]\n",
      "RAG standard: Ease-MM is a new prediction method for protein stability changes induced by single amino acid substitutions. It comprises five specialized support vector machine models and can predict changes with a protein sequence and mutation as inputs. Ease-MM has shown better performance compared to other sequence-based methods and can be accessed through a web server.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\burha\\miniconda3\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\burha\\miniconda3\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\burha\\miniconda3\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\burha\\miniconda3\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\burha\\miniconda3\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\burha\\miniconda3\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG compressor: Ease-mm is a new prediction method developed for accurate prediction of protein stability changes induced by single amino acid substitutions. It utilizes automated in-line AI-measured mapse and GL-shortening to deliver immediate and highly reproducible results.\n"
     ]
    }
   ],
   "source": [
    "query = 'What is ease-mm ?'# 'How does the new prediction method, EASE-MM, select the final prediction model?''\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query)\n",
    "print(compressed_docs) # USE THESE DOCS\n",
    "print(\"RAG compressor:\",rag_chain_compressor.invoke(query))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
