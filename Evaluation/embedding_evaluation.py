'''
This script generates different type of questions on random documents from papers.json generated by the PubMedScraper.py.

How to use:
1. Execute PubMedScraper.py and generate the papers.json
2. Modify embedding_evaluation.py. Insert your key, the amount= questions and num_documents= amount of random documents.
3. Execute embedding_evaluation.py to generate random questions on random scraped documents

Output: A json file (embedding_questions.json) with the dictionary format: {"title of document", {"question_1": ...,"question_2":...}}
It will generate on {num_documents} exactly {amount} of questions using OpenAIs API.
Please make sure to have balance on your account.

Hint:

There is alot of playground on how to form the prompt. We choose a type of question, give the context, and ask OpenAI to form questions of this type.
We expect the response to be in JSON format, but we cannot gurantee it. Therefore, we need some error-handling, in case of bade parsing.
One can extend the types of questions, or even modify this code to ask a commong question over multiple documents.

Problems:

Some questions are general, not context-specific like "Whats the purpose of this study?".
Despite these "bad" questions, we will choose the best performing embedding system.
One could also force ChatGPT in the prompt, to be more context-specific while maintaining the questions short and simple.

The actual point of embeddings are, that the search engine can find relevant documents based on the semantic of the query.
We would need to force ChatGPT to form questions that challenges a Sparse Retriever like the BM25 Retriever.
'''

import json
import random
import openai

# Set your OpenAI GPT-3 API key
openai.api_key = 'KEY'

def generate_questions(title, context, amount):
    '''We ask ChatGPT to form questions over our context, while taking into account different forms of questions.
       1. Confirmation Question [yes or no]
       2. Factoid-type Question [what, which, when, who, how]
       3. List-type Question
       4. Casual Question [why or how]
       5. Hypothetical Question [what if]
       6. Complex question (requires understanding of multiple texts)
    '''
    question_type = ["confirmation questions [yes or no]", "factoid-type questions [what, which, when, who, how]","list-type questions","casual questions [why or how]","hypothethical questions [e.g. what would happen if...]","questions"]
    random_type = random.randint(0,len(question_type)-1)

    prompt = f"""Context: {context}\n\nI want to evaluate my document embeddings. Form {question_type[random_type]} in your own words. Answer in this json format {{"question_1": '', ...}} (Exact Amount: {amount}), don't say anything else."""
    # Careful, when you add {title} in the prompt. ChatGPT tends to make the question title-specific

    # You can adjust temperature and max tokens as per your preferences
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",  # Use the chat model
        messages=[
            {"role": "system", "content": "assistant"},
            {"role": "user", "content": prompt},
        ],
        temperature=0.7,
        max_tokens=100,
        n=1  # Generate two questions
    )
    #print(prompt)
    #print(response)
    try:
        answer = json.loads(response['choices'][0]['message']['content'])
    except json.JSONDecodeError as e:
        print(f"Error with {prompt}\n{response}\n")
        return None
    return answer

def get_random_documents(json_data, num_documents=50):
    documents = json.loads(json_data)
    selected_documents = random.sample(documents, min(num_documents, len(documents)))

    result = []
    for document in selected_documents:
        title = document.get("title", {}).get("full_text", "")
        context = document.get("abstract", {}).get("full_text", "")
        result.append((title, context))

    return result

with open('papers.json', 'r') as file:
    json_data = file.read()

rand_docs = get_random_documents(json_data, num_documents=50)

questions_dict = {}
for title, context in rand_docs:
    generated_questions = generate_questions(title, context,amount=3)
    if generated_questions == None: # In case we cannot parse the response from ChatGPT
        continue
    keys = generated_questions.keys()
    for i in list(keys):
        questions_dict[title] = {key: generated_questions[key] for key in keys}

with open('embedding_questions.json', 'w') as json_file:
    json.dump(questions_dict, json_file, indent=2)
